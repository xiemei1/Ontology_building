{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math \n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "from spacy import displacy \n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText():\n",
    "    f = open('../data/texts.json',)\n",
    "    data = json.load(f)\n",
    "    content_debates = data['debates']\n",
    "    #text= content_debates.replace(\"\\n\",\" \")\n",
    "    return content_debates\n",
    "def sw_removal(text):\n",
    "    sw_spacy = nlp.Defaults.stop_words\n",
    "    words = [word for word in text.split() if word.lower() not in sw_spacy]\n",
    "    new_text = \" \".join(words)\n",
    "    return new_text\n",
    "def getSentences(text):\n",
    "    document = nlp(text)\n",
    "    return [sent.text for sent in document.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendChunk(original, chunk):\n",
    "    return original + ' ' + chunk\n",
    "\n",
    "def printToken(token):\n",
    "    print(token.text, \"->\", token.dep_)\n",
    "\n",
    "def isRelationCandidate(token):\n",
    "    deps = [\"ROOT\", \"adj\", \"attr\", \"agent\", \"amod\"]\n",
    "    return any(subs in token.dep_ for subs in deps)\n",
    "\n",
    "\n",
    "def isConstructionCandidate(token):\n",
    "    deps = [\"compound\", \"prep\", \"conj\", \"mod\"]\n",
    "    return any(subs in token.dep_ for subs in deps)\n",
    "\n",
    "def processSubjectObjectPairs(tokens):\n",
    "    subject = ''\n",
    "    object = ''\n",
    "    relation = ''\n",
    "    subjectConstruction = ''\n",
    "    objectConstruction = ''\n",
    "    for token in tokens:\n",
    "        #printToken(token)\n",
    "        if \"punct\" in token.dep_:\n",
    "            continue\n",
    "        if isRelationCandidate(token):\n",
    "            relation = appendChunk(relation, token.lemma_)\n",
    "        if isConstructionCandidate(token):\n",
    "            if subjectConstruction:\n",
    "                subjectConstruction = appendChunk(subjectConstruction, token.text)\n",
    "            if objectConstruction:\n",
    "                objectConstruction = appendChunk(objectConstruction, token.text)\n",
    "        if \"subj\" in token.dep_:\n",
    "            subject = appendChunk(subject, token.text)\n",
    "            subject = appendChunk(subjectConstruction, subject)\n",
    "            subjectConstruction = ''\n",
    "        if \"obj\" in token.dep_:\n",
    "            object = appendChunk(object, token.text)\n",
    "            object = appendChunk(objectConstruction, object)\n",
    "            objectConstruction = ''\n",
    "\n",
    "    print (subject.strip(), \",\", relation.strip(), \",\", object.strip())\n",
    "    return (subject.strip(), relation.strip(), object.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def printGraph(triples):\n",
    "    G = nx.Graph()\n",
    "    for triple in triples:\n",
    "        G.add_node(triple[0])\n",
    "        G.add_node(triple[1])\n",
    "        G.add_node(triple[2])\n",
    "        G.add_edge(triple[0], triple[1])\n",
    "        G.add_edge(triple[1], triple[2])\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "    plt.figure()\n",
    "    nx.draw(G,pos, edge_color='black',width=3, linewidths=0,\n",
    "            node_size=100, node_color='red',alpha=0.6)\n",
    "    nx.draw_networkx_labels(G,pos, font_size=8)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Document = getText()\n",
    "doc = sw_removal(Document)\n",
    "sentences = getSentences(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , good Hempstead , \n",
      " , Holt , \n",
      " , want welcome presidential , debate\n",
      " , participant , \n",
      " , sponsor Debates nonpartisan nonprofit , \n",
      "commission , draft agree , format campaigns\n",
      " , divide segment , \n",
      "We Achieving minutes , start lead , areas prosperity direction America segment candidates\n",
      "we , open , discussion\n",
      " , share campaign , \n"
     ]
    }
   ],
   "source": [
    "triples1 = []\n",
    "for sentence in sentences[0:10:]:\n",
    "    sen=nlp(sentence)\n",
    "    triples1.append(processSubjectObjectPairs(sen))\n",
    "\n",
    "printGraph(triples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
